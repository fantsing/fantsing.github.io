[{"content":"学习基础知识看的是这几篇博客：\n从零到一：图神经网络（GNN）实战指南——掌握企业级开发技术与代码实现\n图神经网络（GNN）原理解析：从谱卷积到空间卷积\n图神经网络从入门到入门\n","date":"2025-10-25T13:40:43+08:00","permalink":"http://localhost:1313/p/gnn%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E5%88%86%E5%AD%90%E6%B4%BB%E6%80%A7%E9%A2%84%E6%B5%8B/","title":"GNN项目实战-分子活性预测"},{"content":"基础知识学习了这篇博客\nCV攻城狮入门VIT(vision transformer)之旅——近年超火的Transformer你再不了解就晚了！ - 掘金\n论文参考：Attention Is All You Need\n1706.03762\n然后读Transformer底层代码\n环境导入\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import copy import math import torch from torch import nn import torch.nn.functional as F import numpy as np #from torch.utils.tensorboard import SummaryWriter import utils_transformer as utils import math, copy, time import matplotlib.pyplot as plt print(\u0026#34;PyTorch Version: \u0026#34;,torch.__version__) device = torch.device(\u0026#34;cuda:0\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) print(\u0026#39;Device:\u0026#39;, device) num_gpu = torch.cuda.device_count() print(\u0026#39;Number of GPUs Available:\u0026#39;, num_gpu) # # Default directory \u0026#34;runs\u0026#34; # writer = SummaryWriter() HyperParameters设置\n1 2 3 4 batch_size = 2 sequence_length = 6 hidden_size = 16 attention_heads = 8 Embeddings 将输入 token 和输出 token 转换为维度为 d 的向量\n1 2 3 4 5 6 7 8 9 10 11 12 class Embeddings(nn.Module): # 定义一个名为Embeddings的类，继承自nn.Module def __init__(self, d_model_hidden_size, vocab_size): # 初始化函数，接收隐藏层大小和词汇表大小作为参数 super(Embeddings, self).__init__() # 调用父类的初始化方法 # vocab_size: 词汇表中的元素数量 # d_model_hidden_size: 隐藏层的大小 self.lut = nn.Embedding(vocab_size, d_model_hidden_size) # 创建一个嵌入层，将词汇表大小和隐藏层大小作为参数 self.d_model = d_model_hidden_size # 将隐藏层大小存储在实例变量d_model中 def forward(self, x): # 定义前向传播函数，接收输入x # 查找嵌入向量，将输入的单词索引转换为对应的嵌入向量 # 输出形状为 (batch_size, sequence_length, d_model_hidden_size) return self.lut(x) * math.sqrt(self.d_model) # 返回嵌入向量，并乘以隐藏层大小的平方根，以进行缩放 Attenion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 实现注意力机制（缩放点积注意力） def attention(query, key, value, mask=None, dropout=None): d_k = query.size(-1) # 获取query的最后一个维度的大小，通常是嵌入向量的维度 # 计算注意力得分，通过query和key的转置相乘，然后除以d_k的平方根进行缩放 scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k) if mask is not None: # 如果提供了掩码 # 使用掩码填充得分为负无穷大，以避免在softmax中被考虑 scores = scores.masked_fill(mask == 0, -1e9) # 对得分应用softmax，沿着最后一个维度进行归一化 p_attn = F.softmax(scores, dim=-1) if dropout is not None: # 如果提供了dropout层 p_attn = dropout(p_attn) # 对注意力分布应用dropout # 计算注意力结果，通过注意力分布p_attn和value相乘 attention_result = torch.matmul(p_attn, value) # 返回注意力结果和注意力分布 return attention_result, p_attn MultiHeaded Attention\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class MultiHeadedAttention(nn.Module): # 定义一个名为MultiHeadedAttention的类，继承自nn.Module def __init__(self, h, d_model, dropout=0.1): # 初始化函数，接收头数h、模型维度d_model和dropout比率作为参数 \u0026#34;Take in model size and number of heads.\u0026#34; # 简短说明：接收模型大小和头的数量 super(MultiHeadedAttention, self).__init__() # 调用父类的初始化方法 assert d_model % h == 0 # 确保模型维度可以被头数整除 # 我们假设d_v总是等于d_k self.d_k = d_model // h # 计算每个头的维度 self.h = h # 存储头的数量 self.linears = utils.clones(nn.Linear(d_model, d_model), 4) # 创建四个线性变换层 self.attn = None # 初始化注意力权重 self.dropout = nn.Dropout(p=dropout) # 创建dropout层，设置丢弃率 def forward(self, query, key, value, mask=None): # 定义前向传播函数，接收query、key、value和可选的mask作为参数 if mask is not None: # 如果提供了掩码 # 对所有的头应用相同的掩码 mask = mask.unsqueeze(1) nbatches = query.size(0) # 获取batch的大小 # 1) 在批处理中执行所有线性变换，从d_model =\u0026gt; h x d_k # query、key和value的原始形状是 [nbatches, seq_len, d_model] query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))] # 2) 对所有投影向量应用注意力机制 x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout) # 3) 使用view将结果“连接”起来，并应用最终的线性变换 x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k) return self.linears[-1](x) # 返回最后的线性变换结果 ","date":"2025-10-15T13:52:23+08:00","permalink":"http://localhost:1313/p/transformer/","title":"Transformer"},{"content":"VGG学习 概论 2014年，牛津大学计算机视觉组(Visual Geometry Group)和Google DeepMind公司的研究员Karen Simonyan和Andrew Zisserman研发出了新的深度卷积神经网络：VGGNet,,并在ILSVRC2014比赛分类项目中取得了第二名的好成绩(第一名是同年提出的GoogLeNet模型)，同时在定位项目中获得第一名。VGGNet模型通过探索卷积神经网络的深度与性能之间的关系，成功构建了16~19层深的卷积神经网络，并证明了增加网络深度可以在一定程度上提高网络性能，大幅降低错误率。此外，VGGNet具有很强的拓展性和泛化性，适用于其它类型的图像数据。至今，VGGNet仍然被广泛应用于图像特征提取。VGGNet可以看成是加深版本的AlexNet,都是由卷积层、全连接层两大部分构成。\n论文链接：[1409.1556] Very Deep Convolutional Networks for Large-Scale Image Recognition\n原理学习 网络退化 残差连接 结构简洁，VGG网络中，所有卷积层的卷积核大小，步长和填充都相同，并且通过使用最大池化对卷积层进行分层。所有隐藏层的激活单元都采用RLU函数。由于其极简且清晰的结构，VGGNet至今仍广泛用于图像特征提取。 小卷积核，VGGNet中所有的卷积层都使用了小卷积核(3×3)。这种设计有两个优点：一方面，可以大幅减少参数量；另一方面，节省下来的参数可以用于堆叠更多的卷积层，进一步增加了网络的深度和非线性映射能力，从而提高了网络的表达和特征提取能力。 VGG模型中指出两个3×3的卷积堆叠获得的感受野大小，相当于一个5×5的卷积：而3个5×5卷积的堆叠获取到的感受野相当于一个7×7的卷积。这样可以增加非线性映射，也能很好地减少参数(例如5×5的参数为25个，而2个3×3的参数为18)。\n小池化核、相比AlexNet的3×3的池化核，VGGNet全部采用2×2的池化核。 通道数多、VGGNet第一层的通道数为64，后面每层都进行了翻倍，最多达到512个通道。相比较于AlexNet和ZFNet最多得到的通道数是256，VGGNet翻倍的通道数使得更多的信息可以被卷积操作提取出来。 层数更深、特征图更多、网络中，卷积层专注于扩大特征图的通道数、池化层专注于缩小特征图的宽和高，使得模型架构上更深更宽的同时，控制了计算量的增加规模。 模型结构 容易部署到硬件，轻量化！\n代码实现 也是同上一篇AlexNet的参考代码一致，链接：GitHub - Arwin-Yu/Deep-Learning-Image-Classification-Models-Based-CNN-or-Attention: This project organizes classic images classification neural networks based on convolution or attention, and writes training and inference python scripts\n主要研究“vggnet.py”文件\n1 2 3 4 5 6 7 8 9 10 import torch.nn as nn import torch # 官方提供的预训练权重 model_urls = { \u0026#39;vgg11\u0026#39;: \u0026#39;https://download.pytorch.org/models/vgg11-bbd30ac9.pth\u0026#39;, \u0026#39;vgg13\u0026#39;: \u0026#39;https://download.pytorch.org/models/vgg13-c768596a.pth\u0026#39;, \u0026#39;vgg16\u0026#39;: \u0026#39;https://download.pytorch.org/models/vgg16-397923af.pth\u0026#39;, \u0026#39;vgg19\u0026#39;: \u0026#39;https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\u0026#39; } 类的定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class VGG(nn.Module): def __init__(self, features, num_classes=1000, init_weights=False): super(VGG, self).__init__() self.features = features # 特征提取部分（卷积层和池化层） self.classifier = nn.Sequential( # 分类部分（全连接层） nn.Linear(512*7*7, 4096), nn.ReLU(True), nn.Dropout(p=0.5), nn.Linear(4096, 4096), nn.ReLU(True), nn.Dropout(p=0.5), nn.Linear(4096, num_classes) ) if init_weights: self._initialize_weights() # 权重初始化 features：这是网络的特征提取部分，由卷积层和池化层组成 classifier：这是分类器部分，由全连接层组成 num_classes：分类的类别数，默认1000（对应ImageNet数据集） 前向传播方法 1 2 3 4 5 6 7 8 def forward(self, x): # N x 3 x 224 x 224 输入图像：批量大小x通道数x高度x宽度 x = self.features(x) # 通过特征提取部分 # N x 512 x 7 x 7 特征提取后的输出 x = torch.flatten(x, start_dim=1) # 展平操作，从第1维度开始 # N x 512*7*7 展平后的向量 x = self.classifier(x) # 通过分类器 return x 前向传播定义了数据在网络中的流动路径 torch.flatten将卷积输出的多维特征转换为一维向量，以便输入全连接层 权重初始化方法 1 2 3 4 5 6 7 8 9 def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): # 卷积层权重初始化 nn.init.xavier_uniform_(m.weight) # Xavier均匀分布初始化 if m.bias is not None: nn.init.constant_(m.bias, 0) # 偏置初始化为0 elif isinstance(m, nn.Linear): # 全连接层权重初始化 nn.init.xavier_uniform_(m.weight) nn.init.constant_(m.bias, 0) 初始化权重对网络训练非常重要 这里使用Xavier初始化方法，适合ReLU激活函数 生成特征提取层 1 2 3 4 5 6 7 8 9 10 11 def make_features(cfg: list): layers = [] in_channels = 3 # 输入图像是RGB三通道 for v in cfg: if v == \u0026#34;M\u0026#34;: # 如果遇到\u0026#34;M\u0026#34;，添加池化层 layers += [nn.MaxPool2d(kernel_size=2, stride=2)] else: # 否则添加卷积层和激活函数 conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1) layers += [conv2d, nn.ReLU(True)] in_channels = v # 更新输入通道数为当前输出通道数 return nn.Sequential(*layers) # 将所有层按顺序包装 这个函数根据配置列表cfg生成特征提取部分 遍历配置列表，遇到\u0026quot;M\u0026quot;就添加池化层，否则添加卷积层+ReLU激活函数 kernel_size=3, padding=1保证卷积后特征图大小不变 网络配置参数 1 2 3 4 5 6 cfgs = { \u0026#39;vgg11\u0026#39;: [64, \u0026#39;M\u0026#39;, 128, \u0026#39;M\u0026#39;, 256, 256, \u0026#39;M\u0026#39;, 512, 512, \u0026#39;M\u0026#39;, 512, 512, \u0026#39;M\u0026#39;], \u0026#39;vgg13\u0026#39;: [64, 64, \u0026#39;M\u0026#39;, 128, 128, \u0026#39;M\u0026#39;, 256, 256, \u0026#39;M\u0026#39;, 512, 512, \u0026#39;M\u0026#39;, 512, 512, \u0026#39;M\u0026#39;], \u0026#39;vgg16\u0026#39;: [64, 64, \u0026#39;M\u0026#39;, 128, 128, \u0026#39;M\u0026#39;, 256, 256, 256, \u0026#39;M\u0026#39;, 512, 512, 512, \u0026#39;M\u0026#39;, 512, 512, 512, \u0026#39;M\u0026#39;], \u0026#39;vgg19\u0026#39;: [64, 64, \u0026#39;M\u0026#39;, 128, 128, \u0026#39;M\u0026#39;, 256, 256, 256, 256, \u0026#39;M\u0026#39;, 512, 512, 512, 512, \u0026#39;M\u0026#39;, 512, 512, 512, 512, \u0026#39;M\u0026#39;], } 这些配置定义了不同深度的VGG网络 数字表示卷积层的输出通道数 \u0026ldquo;M\u0026quot;表示最大池化层 数字的个数对应卷积层的数量，比如VGG16有16个卷积层和全连接层 模型创建函数 1 2 3 4 5 6 def vgg11(num_classes): cfg = cfgs[\u0026#34;vgg11\u0026#34;] model = VGG(make_features(cfg), num_classes=num_classes) return model # vgg13、vgg16、vgg19函数结构类似 这些函数提供了便捷的方式创建不同深度的VGG模型 使用时只需调用对应的函数，如model = vgg16(10)创建一个用于10分类的VGG16模型 总结 全部使用3×3的小卷积核，多个小卷积核堆叠相当于一个大卷积核的感受野 采用\u0026quot;卷积层堆叠+池化层\u0026quot;的结构，逐步减小特征图尺寸，增加通道数 网络深度是其重要特征，从11层到19层不等 全连接层部分结构固定，都是两个4096维的隐藏层 ","date":"2025-10-03T13:40:43+08:00","permalink":"http://localhost:1313/p/vgg%E5%AD%A6%E4%B9%A0/","title":"VGG学习"},{"content":"AlexNet 学习 概论 2012年提出，在ImageNet图像分类比赛中取得优异成绩，它通过使用RLU激活函数，数据增强和dropout正则化技术，极大地提升了图像识别的精度和速度。AlexNet的成功标志着深度学习在计算机视觉领域的突破，推动了后续更多先进网络结构的研发。实际上也是DL的导火索。\n论文出处：ImageNet classification with deep convolutional neural networks | Communications of the ACM\n原理学习 卷积的计算与属性 数据增强 为了解决过拟合的问题，进行数据增强，旋转、裁剪、对比度等等\nDropout Other question 多GPU实现，是因为当时硬件条件太差，无奈之举，现在已经不需要这样了，但是有GCNN后续问世，也是一种新训练方式。图中虚线feature map的交互（复制）是为了让模型更统一。 局部相应归一化，后续被BN/LN取代，只是一个过渡产物。 代码实现 这里是从github找的，链接如下：GitHub - Arwin-Yu/Deep-Learning-Image-Classification-Models-Based-CNN-or-Attention: This project organizes classic images classification neural networks based on convolution or attention, and writes training and inference python scripts\n主要是学习“alexnet.py”文件，其他的训练脚本等等具有通用的性质。\n导入库 1 2 3 import torch.nn as nn import torch from torchsummary import summary torch.nn是PyTorch中用于构建神经网络的核心模块，nn是其缩写。它提供了大量预定义的神经网络层（如卷积层nn.Conv2d、全连接层nn.Linear、激活函数nn.ReLU、池化层nn.MaxPool2d等）、损失函数（如nn.CrossEntropyLoss、nn.MSELoss）以及模型容器（如nn.Sequential）。 - 通过nn模块，开发者可以快速搭建各种神经网络结构，无需手动实现底层运算。\ntorch是PyTorch的主模块，包含了框架的核心功能。提供了张量（Tensor）数据结构（类似多维数组，是PyTorch的基本运算单位）、自动求导（torch.autograd）、GPU加速支持、数据加载工具（torch.utils.data）等。所有PyTorch的核心操作（如张量运算、模型训练流程控制）都依赖于这个模块。\ntorchsummary是一个第三方工具库，用于可视化神经网络的结构和参数信息。调用summary(model, input_size)可以输出模型各层的名称、输入输出形状、参数数量等，帮助开发者快速了解模型结构是否符合预期，尤其适合调试复杂网络。例如，对于CNN模型，它可以清晰展示每一层卷积、池化后的特征图尺寸变化，便于检查网络设计是否合理。\n类定义与初始化 1 2 3 class AlexNet(nn.Module): def __init__(self, num_classes=1000, init_weights=False): super(AlexNet, self).__init__() num_classes=1000：默认分类类别数为1000\ninit_weights=False：是否初始化权重的开关\n特征提取部分 这部分由卷积层、激活函数和池化层组成，用于从图像中提取特征：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 self.features = nn.Sequential( # 第一层：卷积 + ReLU + 池化 nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2), # 输入[3, 224, 224] 输出[96, 55, 55] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # 输出[96, 27, 27] # 第二层：卷积 + ReLU + 池化 nn.Conv2d(96, 256, kernel_size=5, padding=2), # 输出[256, 27, 27] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # 输出[256, 13, 13] # 第三层：卷积 + ReLU（无池化） nn.Conv2d(256, 384, kernel_size=3, padding=1), # 输出[384, 13, 13] nn.ReLU(inplace=True), # 第四层：卷积 + ReLU（无池化） nn.Conv2d(384, 384, kernel_size=3, padding=1), # 输出[384, 13, 13] nn.ReLU(inplace=True), # 第五层：卷积 + ReLU + 池化 nn.Conv2d(384, 256, kernel_size=3, padding=1), # 输出[256, 13, 13] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # 输出[256, 6, 6] ) nn.Sequential：按顺序包装多个网络层\n卷积层参数说明：nn.Conv2d(输入通道数, 输出通道数, 卷积核大小, 步长, 填充)\nnn.ReLU(inplace=True)：激活函数，inplace=True表示原地操作节省内存\nnn.MaxPool2d：最大池化层，用于降低特征图尺寸\nAlexNet中仅在第1、2、5个卷积层后使用池化，而第3、4个卷积层后不使用，主要出于以下考虑：\n（1）避免特征过度压缩，前两个卷积层的卷积核较大（11×11、5×5），步长也较大（4、默认1），输出的特征图尺寸仍有压缩空间（如第一层从224×224→55×55，池化后→27×27）。而第3、4个卷积层使用3×3的小卷积核，且步长为1、padding=1，输出特征图尺寸与输入相同（13×13）。此时若加入池化，会将特征图压缩到6×6左右，但这两层的作用是细化特征提取，过早压缩会丢失细节信息。\n（2）平衡特征提取深度与计算量，卷积层的核心作用是增加特征维度（通道数），池化层的作用是降低空间维度。两者需要交替配合，避免参数爆炸。第3、4层的通道数从256→384→384，处于特征维度提升阶段，此时保持空间尺寸（13×13）可以让小卷积核捕捉更丰富的局部模式。若在此处池化，会导致后续特征计算的基础空间分辨率不足。\n（3）遵循先压缩大尺寸，后保留细节的逻辑，输入图像（224×224）尺寸较大，前两层通过大卷积核+池化快速压缩空间尺寸（从224→55→27→13），减少冗余计算。当尺寸压缩到13×13后，第3、4层专注于用小卷积核“深耕”特征，此时不需要再压缩尺寸。最后在第5个卷积层后再次池化，将尺寸从13×13→6×6，为后续全连接层的“扁平输入”做准备（6×6×256 = 9216，是全连接层的合适输入维度）。\n分类器部分 这部分由全连接层组成，用于将提取的特征映射到具体类别：\n1 2 3 4 5 6 7 8 9 10 11 self.classifier = nn.Sequential( nn.Dropout(p=0.5), # 随机丢弃50%的神经元，防止过拟合 nn.Linear(256 * 6 * 6, 4096), # 输入是展平后的特征：256通道×6×6尺寸 nn.ReLU(inplace=True), nn.Dropout(p=0.5), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Linear(4096, num_classes), # 输出层，维度等于类别数 ) nn.Dropout(p=0.5)：在训练时随机丢弃50%的神经元，防止过拟合\nnn.Linear：全连接层，参数为(输入特征数, 输出特征数)\n前向传播方法 1 2 3 4 5 def forward(self, x): x = self.features(x) # 特征提取 x = torch.flatten(x, start_dim=1) # 展平特征图，start_dim=1表示从通道维度开始展平 x = self.classifier(x) # 分类预测 return x 定义了数据在网络中的流动路径\ntorch.flatten(x, start_dim=1)：将卷积输出的多维特征展平为一维向量，以便输入全连接层\n权重初始化方法 1 2 3 4 5 6 7 8 9 def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): # 卷积层权重初始化 nn.init.kaiming_normal_(m.weight, mode=\u0026#39;fan_out\u0026#39;, nonlinearity=\u0026#39;relu\u0026#39;) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): # 全连接层权重初始化 nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) 为卷积层和全连接层设置不同的权重初始化策略\n卷积层使用Kaiming正态分布初始化（适合ReLU激活函数）\n全连接层使用均值为0、标准差为0.01的正态分布初始化\n模型创建函数 1 2 3 def alexnet(num_classes): model = AlexNet(num_classes=num_classes) return model 提供了一个便捷的函数来创建AlexNet模型实例\n可以通过传入num_classes参数指定分类任务的类别数\n","date":"2025-10-01T13:40:43+08:00","permalink":"http://localhost:1313/p/alexnet%E5%AD%A6%E4%B9%A0/","title":"AlexNet学习"}]