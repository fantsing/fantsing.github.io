[{"content":"学习基础知识看的是这几篇博客：\n从零到一：图神经网络（GNN）实战指南——掌握企业级开发技术与代码实现\n图神经网络（GNN）原理解析：从谱卷积到空间卷积\n图神经网络从入门到入门\n","date":"2025-10-25T13:40:43+08:00","permalink":"http://localhost:1313/p/gnn%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E5%88%86%E5%AD%90%E6%B4%BB%E6%80%A7%E9%A2%84%E6%B5%8B/","title":"GNN项目实战-分子活性预测"},{"content":"基础知识学习了这篇博客\nCV攻城狮入门VIT(vision transformer)之旅——近年超火的Transformer你再不了解就晚了！ - 掘金\n论文参考：Attention Is All You Need\n1706.03762\n然后读Transformer底层代码\n环境导入\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import copy import math import torch from torch import nn import torch.nn.functional as F import numpy as np #from torch.utils.tensorboard import SummaryWriter import utils_transformer as utils import math, copy, time import matplotlib.pyplot as plt print(\u0026#34;PyTorch Version: \u0026#34;,torch.__version__) device = torch.device(\u0026#34;cuda:0\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) print(\u0026#39;Device:\u0026#39;, device) num_gpu = torch.cuda.device_count() print(\u0026#39;Number of GPUs Available:\u0026#39;, num_gpu) # # Default directory \u0026#34;runs\u0026#34; # writer = SummaryWriter() HyperParameters设置\n1 2 3 4 batch_size = 2 sequence_length = 6 hidden_size = 16 attention_heads = 8 Embeddings 将输入 token 和输出 token 转换为维度为 d 的向量\n1 2 3 4 5 6 7 8 9 10 11 12 class Embeddings(nn.Module): # 定义一个名为Embeddings的类，继承自nn.Module def __init__(self, d_model_hidden_size, vocab_size): # 初始化函数，接收隐藏层大小和词汇表大小作为参数 super(Embeddings, self).__init__() # 调用父类的初始化方法 # vocab_size: 词汇表中的元素数量 # d_model_hidden_size: 隐藏层的大小 self.lut = nn.Embedding(vocab_size, d_model_hidden_size) # 创建一个嵌入层，将词汇表大小和隐藏层大小作为参数 self.d_model = d_model_hidden_size # 将隐藏层大小存储在实例变量d_model中 def forward(self, x): # 定义前向传播函数，接收输入x # 查找嵌入向量，将输入的单词索引转换为对应的嵌入向量 # 输出形状为 (batch_size, sequence_length, d_model_hidden_size) return self.lut(x) * math.sqrt(self.d_model) # 返回嵌入向量，并乘以隐藏层大小的平方根，以进行缩放 Attenion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 实现注意力机制（缩放点积注意力） def attention(query, key, value, mask=None, dropout=None): d_k = query.size(-1) # 获取query的最后一个维度的大小，通常是嵌入向量的维度 # 计算注意力得分，通过query和key的转置相乘，然后除以d_k的平方根进行缩放 scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k) if mask is not None: # 如果提供了掩码 # 使用掩码填充得分为负无穷大，以避免在softmax中被考虑 scores = scores.masked_fill(mask == 0, -1e9) # 对得分应用softmax，沿着最后一个维度进行归一化 p_attn = F.softmax(scores, dim=-1) if dropout is not None: # 如果提供了dropout层 p_attn = dropout(p_attn) # 对注意力分布应用dropout # 计算注意力结果，通过注意力分布p_attn和value相乘 attention_result = torch.matmul(p_attn, value) # 返回注意力结果和注意力分布 return attention_result, p_attn MultiHeaded Attention\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class MultiHeadedAttention(nn.Module): # 定义一个名为MultiHeadedAttention的类，继承自nn.Module def __init__(self, h, d_model, dropout=0.1): # 初始化函数，接收头数h、模型维度d_model和dropout比率作为参数 \u0026#34;Take in model size and number of heads.\u0026#34; # 简短说明：接收模型大小和头的数量 super(MultiHeadedAttention, self).__init__() # 调用父类的初始化方法 assert d_model % h == 0 # 确保模型维度可以被头数整除 # 我们假设d_v总是等于d_k self.d_k = d_model // h # 计算每个头的维度 self.h = h # 存储头的数量 self.linears = utils.clones(nn.Linear(d_model, d_model), 4) # 创建四个线性变换层 self.attn = None # 初始化注意力权重 self.dropout = nn.Dropout(p=dropout) # 创建dropout层，设置丢弃率 def forward(self, query, key, value, mask=None): # 定义前向传播函数，接收query、key、value和可选的mask作为参数 if mask is not None: # 如果提供了掩码 # 对所有的头应用相同的掩码 mask = mask.unsqueeze(1) nbatches = query.size(0) # 获取batch的大小 # 1) 在批处理中执行所有线性变换，从d_model =\u0026gt; h x d_k # query、key和value的原始形状是 [nbatches, seq_len, d_model] query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))] # 2) 对所有投影向量应用注意力机制 x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout) # 3) 使用view将结果“连接”起来，并应用最终的线性变换 x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k) return self.linears[-1](x) # 返回最后的线性变换结果 ","date":"2025-10-15T13:52:23+08:00","permalink":"http://localhost:1313/p/transformer/","title":"Transformer"},{"content":"2012年提出，在ImageNet图像分类比赛中取得优异成绩，它通过使用RLU激活函数，数据增强和dropout正则化技术，极大地提升了图像识别的精度和速度。AlexNet的成功标志着深度学习在计算机视觉领域的突破，推动了后续更多先进网络结构的研发。实际上也是DL的导火索。\n论文出处：ImageNet classification with deep convolutional neural networks | Communications of the ACM\n1. 原理学习 1. 卷积的计算与属性 2. 数据增强 为了解决过拟合的问题，进行数据增强，旋转、裁剪、对比度等等\n3. Dropout 4. Other question 多GPU实现，是因为当时硬件条件太差，无奈之举，现在已经不需要这样了，但是有GCNN后续问世，也是一种新训练方式。图中虚线feature map的交互（复制）是为了让模型更统一。 局部相应归一化，后续被BN/LN取代，只是一个过渡产物。 2. 代码实现 这里是从github找的，链接如下：GitHub - Arwin-Yu/Deep-Learning-Image-Classification-Models-Based-CNN-or-Attention: This project organizes classic images classification neural networks based on convolution or attention, and writes training and inference python scripts\n主要是学习“alexnet.py”文件，其他的训练脚本等等具有通用的性质。\n1. 导入库 1 2 3 import torch.nn as nn import torch from torchsummary import summary torch.nn是PyTorch中用于构建神经网络的核心模块，nn是其缩写。它提供了大量预定义的神经网络层（如卷积层nn.Conv2d、全连接层nn.Linear、激活函数nn.ReLU、池化层nn.MaxPool2d等）、损失函数（如nn.CrossEntropyLoss、nn.MSELoss）以及模型容器（如nn.Sequential）。 - 通过nn模块，开发者可以快速搭建各种神经网络结构，无需手动实现底层运算。\ntorch是PyTorch的主模块，包含了框架的核心功能。提供了张量（Tensor）数据结构（类似多维数组，是PyTorch的基本运算单位）、自动求导（torch.autograd）、GPU加速支持、数据加载工具（torch.utils.data）等。所有PyTorch的核心操作（如张量运算、模型训练流程控制）都依赖于这个模块。\ntorchsummary是一个第三方工具库，用于可视化神经网络的结构和参数信息。调用summary(model, input_size)可以输出模型各层的名称、输入输出形状、参数数量等，帮助开发者快速了解模型结构是否符合预期，尤其适合调试复杂网络。例如，对于CNN模型，它可以清晰展示每一层卷积、池化后的特征图尺寸变化，便于检查网络设计是否合理。\n2. 类定义与初始化 1 2 3 class AlexNet(nn.Module): def __init__(self, num_classes=1000, init_weights=False): super(AlexNet, self).__init__() num_classes=1000：默认分类类别数为1000\ninit_weights=False：是否初始化权重的开关\n3. 特征提取部分（self.features） 这部分由卷积层、激活函数和池化层组成，用于从图像中提取特征：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 self.features = nn.Sequential( # 第一层：卷积 + ReLU + 池化 nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2), # 输入[3, 224, 224] 输出[96, 55, 55] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # 输出[96, 27, 27] # 第二层：卷积 + ReLU + 池化 nn.Conv2d(96, 256, kernel_size=5, padding=2), # 输出[256, 27, 27] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # 输出[256, 13, 13] # 第三层：卷积 + ReLU（无池化） nn.Conv2d(256, 384, kernel_size=3, padding=1), # 输出[384, 13, 13] nn.ReLU(inplace=True), # 第四层：卷积 + ReLU（无池化） nn.Conv2d(384, 384, kernel_size=3, padding=1), # 输出[384, 13, 13] nn.ReLU(inplace=True), # 第五层：卷积 + ReLU + 池化 nn.Conv2d(384, 256, kernel_size=3, padding=1), # 输出[256, 13, 13] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # 输出[256, 6, 6] ) nn.Sequential：按顺序包装多个网络层\n卷积层参数说明：nn.Conv2d(输入通道数, 输出通道数, 卷积核大小, 步长, 填充)\nnn.ReLU(inplace=True)：激活函数，inplace=True表示原地操作节省内存\nnn.MaxPool2d：最大池化层，用于降低特征图尺寸\nAlexNet中仅在第1、2、5个卷积层后使用池化，而第3、4个卷积层后不使用，主要出于以下考虑：\n（1）避免特征过度压缩 - 前两个卷积层的卷积核较大（11×11、5×5），步长也较大（4、默认1），输出的特征图尺寸仍有压缩空间（如第一层从224×224→55×55，池化后→27×27）。而第3、4个卷积层使用3×3的小卷积核，且步长为1、padding=1，输出特征图尺寸与输入相同（13×13）。此时若加入池化，会将特征图压缩到6×6左右，但这两层的作用是细化特征提取（基于前两层的基础特征进一步提取更复杂的模式），过早压缩会丢失细节信息。\n（2）平衡特征提取深度与计算量 - 卷积层的核心作用是增加特征维度（通道数），池化层的作用是降低空间维度。两者需要交替配合，避免参数爆炸。第3、4层的通道数从256→384→384，处于特征维度提升阶段，此时保持空间尺寸（13×13）可以让小卷积核捕捉更丰富的局部模式。若在此处池化，会导致后续特征计算的“基础空间分辨率”不足。\n（3）遵循“先压缩大尺寸，后保留细节”的逻辑 - 输入图像（224×224）尺寸较大，前两层通过大卷积核+池化快速压缩空间尺寸（从224→55→27→13），减少冗余计算。当尺寸压缩到13×13后，第3、4层专注于用小卷积核“深耕”特征（增加通道数、细化模式），此时不需要再压缩尺寸。最后在第5个卷积层后再次池化，将尺寸从13×13→6×6，为后续全连接层的“扁平输入”做准备（6×6×256 = 9216，是全连接层的合适输入维度）。\n4. 分类器部分（self.classifier） 这部分由全连接层组成，用于将提取的特征映射到具体类别：\n1 2 3 4 5 6 7 8 9 10 11 self.classifier = nn.Sequential( nn.Dropout(p=0.5), # 随机丢弃50%的神经元，防止过拟合 nn.Linear(256 * 6 * 6, 4096), # 输入是展平后的特征：256通道×6×6尺寸 nn.ReLU(inplace=True), nn.Dropout(p=0.5), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Linear(4096, num_classes), # 输出层，维度等于类别数 ) nn.Dropout(p=0.5)：在训练时随机丢弃50%的神经元，防止过拟合\nnn.Linear：全连接层，参数为(输入特征数, 输出特征数)\n5. 前向传播方法（forward） 1 2 3 4 5 def forward(self, x): x = self.features(x) # 特征提取 x = torch.flatten(x, start_dim=1) # 展平特征图，start_dim=1表示从通道维度开始展平 x = self.classifier(x) # 分类预测 return x 定义了数据在网络中的流动路径\ntorch.flatten(x, start_dim=1)：将卷积输出的多维特征展平为一维向量，以便输入全连接层\n6. 权重初始化方法 1 2 3 4 5 6 7 8 9 def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): # 卷积层权重初始化 nn.init.kaiming_normal_(m.weight, mode=\u0026#39;fan_out\u0026#39;, nonlinearity=\u0026#39;relu\u0026#39;) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): # 全连接层权重初始化 nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) 为卷积层和全连接层设置不同的权重初始化策略\n卷积层使用Kaiming正态分布初始化（适合ReLU激活函数）\n全连接层使用均值为0、标准差为0.01的正态分布初始化\n7. 模型创建函数 python def alexnet(num_classes) 1 2 3 def alexnet(num_classes): model = AlexNet(num_classes=num_classes) return model 提供了一个便捷的函数来创建AlexNet模型实例\n可以通过传入num_classes参数指定分类任务的类别数\n","date":"2025-10-01T13:40:43+08:00","permalink":"http://localhost:1313/p/alexnet%E5%AD%A6%E4%B9%A0/","title":"AlexNet学习"}]